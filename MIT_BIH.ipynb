{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2d806d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import wfdb\n",
    "from scipy.signal import butter, lfilter\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f64e74c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the normal and abnormal classes\n",
    "normal_classes = ['N', 'L', 'R', 'e', 'j']\n",
    "abnormal_classes = ['A', 'a', 'J', 'S']\n",
    "beat_length = 50  # determined by inspection of data\n",
    "mapping = {'N': 0, 'L': 0, 'R': 0, 'e': 0, 'j': 0, 'A': 1, 'a': 1, 'J': 1, 'S': 1}\n",
    "\n",
    "samples = []          # list of beats (each beat is equal to 50 ECG readings)\n",
    "sample_labels = []    # list of labels of each beat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77b59205",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(100,235):\n",
    "    path = \"../MIT/{}\".format(j)\n",
    "    try:\n",
    "        signals, fields = wfdb.rdsamp(path)\n",
    "\n",
    "        annotation = wfdb.rdann(path, 'atr')\n",
    "\n",
    "        signal = signals[:, 0]  \n",
    "        labels = annotation.symbol\n",
    "        #loop to separate and store beats with their labels\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] in normal_classes or labels[i] in abnormal_classes:\n",
    "                \n",
    "                beat_start = annotation.sample[i]\n",
    "                beat_end = annotation.sample[i+1] if i+1 < len(annotation.sample) else len(signal)\n",
    "                beat = signal[beat_start:beat_end]\n",
    "\n",
    "                \n",
    "                if len(beat) < beat_length:\n",
    "                    padded_beat = np.pad(beat, (0, beat_length - len(beat)), mode='constant')\n",
    "                    samples.append(padded_beat)\n",
    "                else:\n",
    "                    truncated_beat = beat[:beat_length]\n",
    "                    samples.append(truncated_beat)\n",
    "                sample_labels.append(mapping[labels[i]])\n",
    "\n",
    "        # for i in range(len(labels)):\n",
    "        #     if labels[i] in normal_classes or labels[i] in abnormal_classes:\n",
    "            \n",
    "        #         beat_start = annotation.sample[i]-int(beat_length/2)\n",
    "        #         beat_end = annotation.sample[i]+int(beat_length/2)\n",
    "        #         beat = signal[beat_start:beat_end]\n",
    "        #         samples.append(beat)\n",
    "        #         sample_labels.append(mapping[labels[i]])    \n",
    "        \n",
    "    \n",
    "    except:\n",
    "        continue\n",
    "\n",
    "\n",
    "X = np.array(samples)\n",
    "y = np.array(sample_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bfbc4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.84 ,  0.765,  0.52 ,  0.17 , -0.165, -0.365, -0.435, -0.425,\n",
       "       -0.37 , -0.33 , -0.325, -0.335, -0.345, -0.33 , -0.325, -0.315,\n",
       "       -0.31 , -0.32 , -0.335, -0.34 , -0.325, -0.345, -0.335, -0.33 ,\n",
       "       -0.335, -0.33 , -0.325, -0.33 , -0.33 , -0.345, -0.355, -0.335,\n",
       "       -0.325, -0.305, -0.32 , -0.32 , -0.33 , -0.34 , -0.335, -0.34 ,\n",
       "       -0.345, -0.355, -0.355, -0.34 , -0.33 , -0.33 , -0.33 , -0.34 ,\n",
       "       -0.35 , -0.325])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34d42356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aefb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "572b9272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.84 ,  0.765,  0.52 ,  0.17 , -0.165, -0.365, -0.435, -0.425,\n",
       "       -0.37 , -0.33 , -0.325, -0.335, -0.345, -0.33 , -0.325, -0.315,\n",
       "       -0.31 , -0.32 , -0.335, -0.34 , -0.325, -0.345, -0.335, -0.33 ,\n",
       "       -0.335, -0.33 , -0.325, -0.33 , -0.33 , -0.345, -0.355, -0.335,\n",
       "       -0.325, -0.305, -0.32 , -0.32 , -0.33 , -0.34 , -0.335, -0.34 ,\n",
       "       -0.345, -0.355, -0.355, -0.34 , -0.33 , -0.33 , -0.33 , -0.34 ,\n",
       "       -0.35 , -0.325])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "702c5f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93412"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff448669",
   "metadata": {},
   "source": [
    "# Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "388eafb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e0e25b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     18150\n",
      "           1       0.86      0.53      0.65       533\n",
      "\n",
      "    accuracy                           0.98     18683\n",
      "   macro avg       0.93      0.76      0.82     18683\n",
      "weighted avg       0.98      0.98      0.98     18683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "clf.fit(X_train_pca, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_pca)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac15588d",
   "metadata": {},
   "source": [
    "# XgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1422972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb160cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     18150\n",
      "           1       0.85      0.56      0.68       533\n",
      "\n",
      "    accuracy                           0.98     18683\n",
      "   macro avg       0.92      0.78      0.84     18683\n",
      "weighted avg       0.98      0.98      0.98     18683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize the XGBClassifier\n",
    "xgb_clf = xgb.XGBClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b22563e",
   "metadata": {},
   "source": [
    "# LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "721bcc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bbd1822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2248, number of negative: 72481\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010088 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 74729, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.030082 -> initscore=-3.473284\n",
      "[LightGBM] [Info] Start training from score -3.473284\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0694284\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.98      1.00      0.99     18150\n",
      "    Abnormal       0.87      0.43      0.57       533\n",
      "\n",
      "    accuracy                           0.98     18683\n",
      "   macro avg       0.93      0.71      0.78     18683\n",
      "weighted avg       0.98      0.98      0.98     18683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the classifier using LightGBM\n",
    "dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "dtest = lgb.Dataset(X_test, label=y_test, reference=dtrain)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.1,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "callbacks = [lgb.early_stopping(stopping_rounds=10)]\n",
    "\n",
    "bst = lgb.train(params, dtrain, num_boost_round=100, valid_sets=[dtest], callbacks=callbacks)\n",
    "y_pred_prob = bst.predict(X_test, num_iteration=bst.best_iteration)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_test, y_pred, target_names=['Normal', 'Abnormal'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f182e8c",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd2952c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5da5e487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data for CNN input\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "# Convert labels to categorical format\n",
    "y = to_categorical(y, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2856b2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1869/1869\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9640 - loss: 0.1381 - val_accuracy: 0.9742 - val_loss: 0.0945\n",
      "Epoch 2/10\n",
      "\u001b[1m1869/1869\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9762 - loss: 0.0854 - val_accuracy: 0.9789 - val_loss: 0.0827\n",
      "Epoch 3/10\n",
      "\u001b[1m1869/1869\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9787 - loss: 0.0818 - val_accuracy: 0.9803 - val_loss: 0.0797\n",
      "Epoch 4/10\n",
      "\u001b[1m1869/1869\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9798 - loss: 0.0783 - val_accuracy: 0.9777 - val_loss: 0.0803\n",
      "Epoch 5/10\n",
      "\u001b[1m1869/1869\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9793 - loss: 0.0771 - val_accuracy: 0.9806 - val_loss: 0.0765\n",
      "Epoch 6/10\n",
      "\u001b[1m1869/1869\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9803 - loss: 0.0745 - val_accuracy: 0.9813 - val_loss: 0.0732\n",
      "Epoch 7/10\n",
      "\u001b[1m1869/1869\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9795 - loss: 0.0721 - val_accuracy: 0.9799 - val_loss: 0.0732\n",
      "Epoch 8/10\n",
      "\u001b[1m1869/1869\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9799 - loss: 0.0746 - val_accuracy: 0.9813 - val_loss: 0.0727\n",
      "Epoch 9/10\n",
      "\u001b[1m1869/1869\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9815 - loss: 0.0671 - val_accuracy: 0.9823 - val_loss: 0.0697\n",
      "Epoch 10/10\n",
      "\u001b[1m1869/1869\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9815 - loss: 0.0679 - val_accuracy: 0.9821 - val_loss: 0.0689\n",
      "\u001b[1m584/584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.99      1.00      0.99     18150\n",
      "    Abnormal       0.81      0.55      0.66       533\n",
      "\n",
      "    accuracy                           0.98     18683\n",
      "   macro avg       0.90      0.77      0.82     18683\n",
      "weighted avg       0.98      0.98      0.98     18683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential([\n",
    "    Conv1D(32, kernel_size=3, activation='relu', input_shape=(beat_length, 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_test_labels, y_pred, target_names=['Normal', 'Abnormal'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20b3e83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5eefc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37fde8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd3e1f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgb_model.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Assuming xgb_clf is your trained XGBClassifier\n",
    "joblib.dump(xgb_clf, 'xgb_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a06e37b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8c182f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1c7e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
